{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from difflib import Differ\n",
    "import nltk\n",
    "from spacy.lang.en import English\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "LST = ['crowd', 'expert', 'LLM']\n",
    "\n",
    "def score_minimality(orig_sent: str, edited_sent: str, normalized: bool = True) -> float:\n",
    "        \"\"\"\n",
    "          Calculate Levenshtein distance(token-level) indicating the minimality of changes between two sentences.\n",
    "          This method takes in an original sentence and an edited sentence, both as strings.\n",
    "          It calculates the Levenshtein edit distance between the tokenized versions of these sentences,\n",
    "          representing the minimum number of single-token edits needed to transform one into the other.\n",
    "          Parameters:\n",
    "          - orig_sent (str): The original sentence before editing.\n",
    "          - edited_sent (str): The edited version of the sentence.\n",
    "          - normalized (bool, optional): If True, returns a normalized score relative to the length of\n",
    "            the original sentence. If False, returns the raw edit distance value.\n",
    "          Returns:\n",
    "          - float: The calculated minimality score. If ‘normalized’ is True, the score represents the\n",
    "            proportion of changes relative to the original sentence length.u\n",
    "            Source:\n",
    "          \"\"\"\n",
    "        nlp = English()\n",
    "        tokenizer = nlp.tokenizer\n",
    "        tokenized_original = [t.text for t in tokenizer(orig_sent)]\n",
    "        tokenized_edited = [t.text for t in tokenizer(edited_sent)]\n",
    "        levenshtein_dist = nltk.edit_distance(tokenized_original, tokenized_edited)\n",
    "        if normalized:\n",
    "            return levenshtein_dist / len(tokenized_original)\n",
    "        else:\n",
    "            return levenshtein_dist\n",
    "\n",
    "\n",
    "def compute_dist(s1, s2):\n",
    "    #assert((df[SENT_COLUMN] != df[CF_SENT_COLUMN]).all())\n",
    "    assert len(s1) == len(s2)\n",
    "    dist = []\n",
    "\n",
    "    for x, y in zip(s1,s2):\n",
    "            dist.append(score_minimality(x, y))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = ['test']\n",
    "split_name = SPLITS[0]\n",
    "\n",
    "\n",
    "path_raw = '../llms-raw/{}/NLI/{}/{}.csv'\n",
    "path_preds = '../llms-ppl-preds/{}/NLI/{}/{}.tsv'\n",
    "\n",
    "lst_dfs = []\n",
    "LLMS = ['gpt3.5-20240313', 'gpt4-20240318', 'llama2_70b-20240318', 'llama2-20231209', 'mistral_56b-20240320', 'mistral-20240118']\n",
    "\n",
    "for LLM in LLMS:\n",
    "\n",
    "\n",
    "    df_llm_hypothesis = pd.read_csv(path_raw.format(LLM, 'revised_hypothesis', split_name))\n",
    "    df_llm_premise = pd.read_csv(path_raw.format(LLM, 'revised_premise', split_name))\n",
    "\n",
    "    for df in [df_llm_hypothesis, df_llm_premise]:\n",
    "        df.replace('', np.nan, inplace=True)   \n",
    "        df.dropna(inplace=True)\n",
    "    \n",
    "    df_llm_hypothesis_preds = pd.read_csv(path_preds.format(LLM, 'revised_hypothesis', split_name), sep='\\t')\n",
    "    df_llm_premise_preds = pd.read_csv(path_preds.format(LLM, 'revised_premise', split_name), sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "    assert len(df_llm_hypothesis) == len(df_llm_hypothesis_preds)\n",
    "    assert len(df_llm_premise) == len(df_llm_premise_preds)\n",
    "\n",
    "    premise_f = df_llm_premise.apply(lambda x: x['original_sentence1'] + ' ' + x['original_sentence2'], axis=1)\n",
    "    premise_cf = df_llm_premise.apply(lambda x: x['contrast text'] + ' ' + x['original_sentence2'], axis=1)\n",
    "\n",
    "\n",
    "    hpyothesis_f = df_llm_hypothesis.apply(lambda x: x['original_sentence1'] + ' ' + x['original_sentence2'], axis=1)\n",
    "    hypothesis_cf = df_llm_hypothesis.apply(lambda x: x['original_sentence1'] + ' ' + x['contrast text'], axis=1)\n",
    "\n",
    "    dist_premise = compute_dist(premise_f, premise_cf)\n",
    "    dist_hypothesis = compute_dist(hpyothesis_f, hypothesis_cf)\n",
    "\n",
    "\n",
    "    df_llm_hypothesis_preds['dist'] = dist_hypothesis\n",
    "    df_llm_premise_preds['dist'] = dist_premise\n",
    "    \n",
    "    df_llm_premise_preds.to_csv(path_preds.format(LLM, 'revised_premise', split_name), sep='\\t', index = False)\n",
    "    df_llm_hypothesis_preds.to_csv(path_preds.format(LLM, 'revised_hypothesis', split_name), sep='\\t', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
