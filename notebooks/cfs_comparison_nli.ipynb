{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from difflib import Differ\n",
    "import nltk\n",
    "from spacy.lang.en import English\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "LST = ['crowd', 'expert', 'LLM']\n",
    "\n",
    "TEXT_COLUMN = 'sentence1'\n",
    "LABEL_COLUMN = 'gold_label'\n",
    "\n",
    "CF_TEXT_COLUMN = 'sentecnce1_contrast' \n",
    "CF_SENT_COLUMN = 'contrast_label' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_sentences(sentence1, sentence2):\n",
    "    differ = Differ()\n",
    "    diff = list(differ.compare(sentence1.split(), sentence2.split()))\n",
    "\n",
    "    added_words = [word[2:] for word in diff if word.startswith('+ ')]\n",
    "    removed_words = [word[2:] for word in diff if word.startswith('- ')]\n",
    "\n",
    "    return added_words, removed_words\n",
    "\n",
    "def compare_cfs(df, f_name, cf_name):\n",
    "    \n",
    "    added_removed = df.apply(lambda x : compare_sentences(x[f_name], x[cf_name]), axis = 1)\n",
    "    added = [x[0] for x in added_removed]\n",
    "    removed = [x[1] for x in added_removed]\n",
    "\n",
    "    df['added'] = added \n",
    "    df['removed'] = removed\n",
    "\n",
    "    df['#added'] = [len(x) for x in added]\n",
    "    df['#removed'] = [len(x) for x in removed]\n",
    "\n",
    "\n",
    "def score_minimality(orig_sent: str, edited_sent: str, normalized: bool = True) -> float:\n",
    "        \"\"\"\n",
    "          Calculate Levenshtein distance(token-level) indicating the minimality of changes between two sentences.\n",
    "          This method takes in an original sentence and an edited sentence, both as strings.\n",
    "          It calculates the Levenshtein edit distance between the tokenized versions of these sentences,\n",
    "          representing the minimum number of single-token edits needed to transform one into the other.\n",
    "          Parameters:\n",
    "          - orig_sent (str): The original sentence before editing.\n",
    "          - edited_sent (str): The edited version of the sentence.\n",
    "          - normalized (bool, optional): If True, returns a normalized score relative to the length of\n",
    "            the original sentence. If False, returns the raw edit distance value.\n",
    "          Returns:\n",
    "          - float: The calculated minimality score. If ‘normalized’ is True, the score represents the\n",
    "            proportion of changes relative to the original sentence length.u\n",
    "            Source:\n",
    "          \"\"\"\n",
    "        nlp = English()\n",
    "        tokenizer = nlp.tokenizer\n",
    "        tokenized_original = [t.text for t in tokenizer(orig_sent)]\n",
    "        tokenized_edited = [t.text for t in tokenizer(edited_sent)]\n",
    "        levenshtein_dist = nltk.edit_distance(tokenized_original, tokenized_edited)\n",
    "        if normalized:\n",
    "            return levenshtein_dist / len(tokenized_original)\n",
    "        else:\n",
    "            return levenshtein_dist\n",
    "\n",
    "\n",
    "def compute_dist(df, name1, name2):\n",
    "    df['dist'] = df.apply(lambda x : score_minimality(x[name1], x[name2]), axis = 1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = ['test']\n",
    "#TASK_expert = 'IMDb'\n",
    "LLM = 'llama2-20231209'\n",
    "#LLM = 'mistral-20240118'\n",
    "LST = [LLM.split('-')[0] if x=='LLM' else x for x in LST]\n",
    "path_raw = '../llms-raw/{}/NLI/{}/{}.csv'\n",
    "\n",
    "lst_dfs = []\n",
    "for split_name in SPLITS:\n",
    "\n",
    "    df_crowd_orig = pd.read_csv('../counterfactually-augmented-data/NLI/original/{}.tsv'.format(split_name), sep='\\t')\n",
    "    df_crowd_premise = pd.read_csv('../counterfactually-augmented-data/NLI/revised_premise/{}.tsv'.format(split_name), sep='\\t')\n",
    "    df_crowd_hypothesis = pd.read_csv('../counterfactually-augmented-data/NLI/revised_hypothesis/{}.tsv'.format(split_name), sep='\\t')\n",
    "\n",
    "    df_llm_hypothesis = pd.read_csv(path_raw.format(LLM, 'revised_hypothesis', split_name))\n",
    "    df_llm_premise = pd.read_csv(path_raw.format(LLM, 'revised_premise', split_name))\n",
    "\n",
    "    df_llm_hypothesis.replace('', np.nan, inplace=True)   \n",
    "    df_llm_hypothesis.dropna(inplace=True)\n",
    "\n",
    "    df_llm_premise.replace('', np.nan, inplace=True)   \n",
    "    df_llm_premise.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    #df_original = df_llm[['original_sentence1', 'original_sentence2', 'original label']]\n",
    "    #df_original.rename(columns={'original_sentence1' : 'sentence1', 'original_sentence2' : 'sentence2','original label' : 'gold_label'}, inplace=True)\n",
    "\n",
    "    #if 'revised_hypothesis' in path_raw:\n",
    "    #        df_new = df_llm[['original_sentence1', 'contrast text', 'contrast label']].copy(deep=True)\n",
    "    #        df_new.rename(columns={'contrast text' : 'original_sentence2'}, inplace=True)\n",
    "    #elif 'revised_premise' in path_raw:\n",
    "    #        df_new = df_llm[['contrast text', 'original_sentence2', 'contrast label']].copy(deep=True)\n",
    "    #        df_new.rename(columns={'contrast text' : 'original_sentence1'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre2hypo = {}\n",
    "hypo2pre = {}\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.replace('  ', ' ').strip()\n",
    "\n",
    "for i, row in df_crowd_orig.iterrows():\n",
    "    pre2hypo[preprocess(row['sentence1'])] = preprocess(row['sentence2'])\n",
    "    hypo2pre[preprocess(row['sentence2'])] = preprocess(row['sentence1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowd_orig.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowd_premise.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowd_premise['sentence1_f'] = df_crowd_premise.apply(lambda x: hypo2pre[preprocess(x['sentence2'])], axis=1) \n",
    "\n",
    "lst_dfs.append((df_crowd_premise, 'crowd_premise', ('sentence1_f', 'sentence1')))\n",
    "df_crowd_premise\n",
    "## factuals: sentence1_y, sentence2, gold_label_y\n",
    "## counterfactuals: sentence1_x, sentence2, gold_label_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowd_hypothesis['sentence2_f'] = df_crowd_hypothesis.apply(lambda x: pre2hypo[preprocess(x['sentence1'])], axis=1) \n",
    "\n",
    "lst_dfs.append((df_crowd_hypothesis, 'crowd_hypothesis', ('sentence2_f', 'sentence2')))\n",
    "df_crowd_premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_dfs.append((df_llm_premise, '{}_premise'.format(LLM.split('-')[0]), ('original_sentence1', 'contrast text')))\n",
    "\n",
    "df_llm_premise.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_dfs.append((df_llm_hypothesis, '{}_hypothesis'.format(LLM.split('-')[0]), ('original_sentence2', 'contrast text')))\n",
    "df_llm_hypothesis.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additions and Omits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in lst_dfs:\n",
    "    print('--'*20)\n",
    "    print(x[1])\n",
    "    print(x[2][0]) \n",
    "    print(x[2][1]) \n",
    "    compare_cfs(x[0], x[2][0], x[2][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lst_dfs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = ['#added', '#removed']\n",
    "variants = ['premise', 'hypothesis']\n",
    "import matplotlib.pyplot as plt\n",
    "for p in plots: \n",
    "    for v in variants:\n",
    "        # Plot the distributions using histograms\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plot for column1\n",
    "\n",
    "        for x in lst_dfs:\n",
    "            if v.lower() in x[1].lower():\n",
    "                plt.hist(x[0][p], alpha=0.5, label=x[1] + ' ({})'.format(x[0][p].mean().round(2)))\n",
    "\n",
    "\n",
    "        #plt.title('Distri#Additions in Counterfactuals')\n",
    "        plt.xlabel(p)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.savefig('./analysis/nli/additions_histo_{}_{}_{}.png'.format(LLM, v, p))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in lst_dfs: \n",
    "    print('--'*20)\n",
    "    print(x[1])\n",
    "    print(x[2][0]) \n",
    "    print(x[2][1]) \n",
    "    compute_dist(x[0], x[2][0], x[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = ['dist']\n",
    "variants = ['premise', 'hypothesis']\n",
    "\n",
    "for p in plots: \n",
    "    for v in variants:\n",
    "        # Plot the distributions using histograms\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plot for column1\n",
    "\n",
    "        for x in lst_dfs:\n",
    "            if v.lower() in x[1].lower():\n",
    "                plt.hist(x[0][p], alpha=0.5, label=x[1] + ' ({})'.format(x[0][p].mean().round(2)))\n",
    "\n",
    "\n",
    "        #plt.title('Distri#Additions in Counterfactuals')\n",
    "        plt.xlabel(p)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.savefig('./analysis/nli/additions_histo_distance_{}_{}_{}.png'.format(LLM, v, p))\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
